{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TensorFlow with GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXnDmXR7RDr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1e1d7461-6f4c-4817-9570-3438ff57a225"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y04m-jvKRDsJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "d2a22830-667f-469c-f32e-7fc9b86d43b0"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.6661160310000014\n",
            "GPU (s):\n",
            "0.05489341000000536\n",
            "GPU speedup over CPU: 48x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brCkhvZXKJzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "8dfdb76f-e2a5-41a1-ce85-6e965b72a4d2"
      },
      "source": [
        "from google.colab import drive #For using the google drive for data\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjo-YLrBKJ37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np#Array handling\n",
        "import pandas as pd#Working with dataframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-Pzo8VHKJ7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/drive/My Drive/dataset/train.csv')\n",
        "test=pd.read_csv('/content/drive/My Drive/dataset/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-NkX3qaKXUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "353502a4-a71b-4363-e7f5-59a8d9730f24"
      },
      "source": [
        "train.head() #Check above mapping worked or not"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>manipuri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>kathakali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0   96.jpg       manipuri\n",
              "1  163.jpg  bharatanatyam\n",
              "2  450.jpg         odissi\n",
              "3  219.jpg      kathakali\n",
              "4  455.jpg         odissi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0r73apKJ9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_map={'manipuri':0,'bharatanatyam':1,'odissi':2, 'kathakali':3, 'kathak':4,'sattriya':5, 'kuchipudi':6, 'mohiniyattam':7}\n",
        "inverse_map={0:'manipuri',1:'bharatanatyam',2:'odissi',3:'kathakali',4: 'kathak',5:'sattriya',6:'kuchipudi',7:'mohiniyattam'}\n",
        "train['target']=train['target'].map(class_map) #maps the two series of class_map[dance forms,ints] dance_forms->ints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ydfHCc8KKAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e67fe146-544f-4044-9de8-5c57911f1d62"
      },
      "source": [
        "train.head() #Check above mapping worked or not"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>96.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>163.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>450.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>455.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image  target\n",
              "0   96.jpg       0\n",
              "1  163.jpg       1\n",
              "2  450.jpg       2\n",
              "3  219.jpg       3\n",
              "4  455.jpg       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5NXlUK8KKCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_h,img_w=(224,224) #For using the standard models to make use of transfer learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXXFtQkBKKFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os#This module provides a portable way of using operating system dependent functionality.\n",
        "import seaborn as sns #For graphs\n",
        "import cv2 #it is used for computer vision applications like image processing,video capture analysis and like face and object detection\n",
        "from tqdm import tqdm #Shows the progess bar of how much a loop is executed or a pipeline is executed.\n",
        "import matplotlib.pyplot as plt #For plotting."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6grs4cdCKKK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "da6fd2ee-338a-4ba2-90f6-a900e8881e05"
      },
      "source": [
        "train_img=[] #In this list we will have images of required type as we needed\n",
        "train_label=[] #lables for images \n",
        "j=0\n",
        "path='/content/drive/My Drive/dataset/train'\n",
        "for i in tqdm(train['Image']):#using tqdm we can get a progress bar showing how much its done\n",
        "    final_path=os.path.join(path,i) #setting up path\n",
        "    img=cv2.imread(final_path) #reading the image\n",
        "    img=cv2.resize(img,(img_h,img_w)) #resizing the image\n",
        "    img=img.astype('float32') #Converting all the pixels as float32\n",
        "    train_img.append(img) #Append it to the list.\n",
        "    train_label.append(train['target'][j]) #similarly append the label\n",
        "    j=j+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 364/364 [00:02<00:00, 138.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWfBw3yMKKOI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "513db2ed-eb1b-4ce1-df37-7342a48b568e"
      },
      "source": [
        "test_img=[]\n",
        "path='/content/drive/My Drive/dataset/test'\n",
        "for i in tqdm(test['Image']):\n",
        "    final_path=os.path.join(path,i)\n",
        "    img=cv2.imread(final_path)\n",
        "    img=cv2.resize(img,(img_h,img_w))\n",
        "    img=img.astype('float32')\n",
        "    test_img.append(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 156/156 [00:01<00:00, 132.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11VukmIXKKvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(train_img,train_label,test_size=0.05,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM-5i3GdKKxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Rescale is a value by which we will multiply the data before any other processing. \n",
        "Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our model to process \n",
        "(given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor'''\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,# divide each input by its std\n",
        "        rescale=1./255,\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.3, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXK2vpZAKK1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We don't do any changes for the test data.\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)\n",
        "valid_datagen= ImageDataGenerator(rescale=1./255)\n",
        "train_datagen.fit(x_train)\n",
        "test_datagen.fit(test_img)\n",
        "valid_datagen.fit(x_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsZWcTfBKK33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a98c15f3-3afe-4c54-f08c-ded744caa9fb"
      },
      "source": [
        "train_img=np.array(train_img)\n",
        "x_train= np.array(x_train)\n",
        "x_valid= np.array(x_valid)\n",
        "y_train= np.array(y_train)\n",
        "y_valid= np.array(y_valid)\n",
        "test_img=np.array(test_img)\n",
        "train_label=np.array(train_label)\n",
        "print(\"Shape of training data=\",x_train.shape,\" and shape of labels of training data= \",y_train.shape)\n",
        "print(\"Shape of validation data=\",x_valid.shape,\" and shape of labels of validation data= \",y_valid.shape)\n",
        "print(\"Shape of test data=\",test_img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data= (345, 224, 224, 3)  and shape of labels of training data=  (345,)\n",
            "Shape of validation data= (19, 224, 224, 3)  and shape of labels of validation data=  (19,)\n",
            "Shape of test data= (156, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KY2_iHPKK93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Flatten -> is the function that converts the pooled feature map to a single column that is passed to the fully connected layer.\n",
        "Dense -> adds the fully connected layer to the neural network.\n",
        "Dropout->regularization\n",
        "BatchNormalization-> sends data(Images) as the batches\n",
        "\n",
        "Model -> Model groups layers into an object with training and inference features.\n",
        "Sequential -> Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "\n",
        "to_categorical -> Converts a class vector (integers) to binary class matrix.\n",
        "\n",
        "Conv2D -> This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs\n",
        "MaxPooling2D -> Downsamples the input representation by taking the maximum value over the window defined by pool_size for each dimension along the features axis\n",
        "\n",
        "ReduceLROnPlateau -> Reduce learning rate when a metric(accuracy) has stopped improving.\n",
        "'''\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUszqFhzKLBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n",
        "                                         factor=0.1,\n",
        "                                         patience=2,\n",
        "                                         cooldown=2,\n",
        "                                         min_lr=0.00001,\n",
        "                                         verbose=1)\n",
        "callbacks = [reduce_learning_rate]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMO2dYzC7rlY",
        "colab_type": "text"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ky9Lu9iOK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "base_model=VGG16(include_top=False,weights='imagenet',input_shape=(img_h,img_w,3),pooling='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAw25WnAiOUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model.layers[:-4]:\n",
        "    layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFNN3GVsiORF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(8,activation='sigmoid'))\n",
        "model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZCH9xHjpo1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vgg19-3\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "#model_3.add(BatchNormalization())\n",
        "#model_3.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "#model_3.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "#model_3.add(BatchNormalization())\n",
        "model.add(Dense(8,activation='softmax'))\n",
        "\n",
        "model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32YqFO_LiOOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e00d5ca-679b-4eb6-e6eb-65d63e74bc11"
      },
      "source": [
        "model.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=16),epochs=200,callbacks=callbacks,\n",
        "          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=16),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "22/22 [==============================] - 14s 658ms/step - loss: 2.3353 - accuracy: 0.1797 - val_loss: 1.8624 - val_accuracy: 0.2632 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 14s 638ms/step - loss: 1.7499 - accuracy: 0.2957 - val_loss: 1.3675 - val_accuracy: 0.5789 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 1.6098 - accuracy: 0.3681 - val_loss: 1.2788 - val_accuracy: 0.4737 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 1.5389 - accuracy: 0.4058 - val_loss: 1.0228 - val_accuracy: 0.4737 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 14s 645ms/step - loss: 1.4248 - accuracy: 0.4493 - val_loss: 1.3055 - val_accuracy: 0.4737 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 1.1962 - accuracy: 0.5362 - val_loss: 1.6331 - val_accuracy: 0.5789 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 14s 642ms/step - loss: 1.1268 - accuracy: 0.5710 - val_loss: 1.1840 - val_accuracy: 0.5789 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 14s 641ms/step - loss: 1.1500 - accuracy: 0.5710 - val_loss: 0.9350 - val_accuracy: 0.6316 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 14s 647ms/step - loss: 1.0492 - accuracy: 0.6174 - val_loss: 0.8473 - val_accuracy: 0.6316 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 14s 648ms/step - loss: 0.9283 - accuracy: 0.6348 - val_loss: 0.9534 - val_accuracy: 0.7368 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 14s 648ms/step - loss: 0.8816 - accuracy: 0.6667 - val_loss: 1.3366 - val_accuracy: 0.5789 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 14s 648ms/step - loss: 0.8324 - accuracy: 0.6754 - val_loss: 0.8833 - val_accuracy: 0.6316 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.8291 - accuracy: 0.6783 - val_loss: 0.6666 - val_accuracy: 0.7895 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 14s 641ms/step - loss: 0.8739 - accuracy: 0.7014 - val_loss: 1.5337 - val_accuracy: 0.7368 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 14s 644ms/step - loss: 0.7362 - accuracy: 0.7362 - val_loss: 0.5201 - val_accuracy: 0.7368 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 14s 638ms/step - loss: 0.7911 - accuracy: 0.7043 - val_loss: 0.6838 - val_accuracy: 0.6842 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 14s 643ms/step - loss: 0.6655 - accuracy: 0.7681 - val_loss: 0.7812 - val_accuracy: 0.6316 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 14s 621ms/step - loss: 0.6091 - accuracy: 0.7710 - val_loss: 0.9318 - val_accuracy: 0.5263 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 14s 625ms/step - loss: 0.6361 - accuracy: 0.7652 - val_loss: 0.7288 - val_accuracy: 0.6842 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.7710\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "22/22 [==============================] - 14s 627ms/step - loss: 0.6603 - accuracy: 0.7710 - val_loss: 0.4761 - val_accuracy: 0.8421 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.5913 - accuracy: 0.7855 - val_loss: 0.6704 - val_accuracy: 0.6842 - lr: 1.0000e-04\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 14s 627ms/step - loss: 0.6161 - accuracy: 0.7913 - val_loss: 0.6666 - val_accuracy: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.4853 - accuracy: 0.8406 - val_loss: 0.7624 - val_accuracy: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 14s 642ms/step - loss: 0.4084 - accuracy: 0.8609 - val_loss: 0.6923 - val_accuracy: 0.7368 - lr: 1.0000e-04\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.4533 - accuracy: 0.8522 - val_loss: 0.8122 - val_accuracy: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8580\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.4167 - accuracy: 0.8580 - val_loss: 0.7674 - val_accuracy: 0.6316 - lr: 1.0000e-04\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.3994 - accuracy: 0.8609 - val_loss: 0.7722 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3895 - accuracy: 0.8696 - val_loss: 0.7686 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.4164 - accuracy: 0.8493 - val_loss: 0.7758 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.3844 - accuracy: 0.8754 - val_loss: 0.7802 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3565 - accuracy: 0.8783 - val_loss: 0.7668 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 14s 640ms/step - loss: 0.3435 - accuracy: 0.8870 - val_loss: 0.7637 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3950 - accuracy: 0.8551 - val_loss: 0.7593 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.8725\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.4010 - accuracy: 0.8725 - val_loss: 0.7652 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.3918 - accuracy: 0.8725 - val_loss: 0.7624 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.4019 - accuracy: 0.8493 - val_loss: 0.7610 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3345 - accuracy: 0.8870 - val_loss: 0.7664 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.3988 - accuracy: 0.8493 - val_loss: 0.7887 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.4091 - accuracy: 0.8638 - val_loss: 0.7857 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.4174 - accuracy: 0.8551 - val_loss: 0.7937 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3668 - accuracy: 0.8783 - val_loss: 0.7851 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3163 - accuracy: 0.8783 - val_loss: 0.7949 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3582 - accuracy: 0.8841 - val_loss: 0.7971 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3888 - accuracy: 0.8667 - val_loss: 0.8001 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3794 - accuracy: 0.8580 - val_loss: 0.8022 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.4173 - accuracy: 0.8580 - val_loss: 0.8008 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3545 - accuracy: 0.8812 - val_loss: 0.8053 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.3612 - accuracy: 0.8841 - val_loss: 0.7833 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3715 - accuracy: 0.8725 - val_loss: 0.7819 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3501 - accuracy: 0.9014 - val_loss: 0.7791 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 14s 645ms/step - loss: 0.3714 - accuracy: 0.8754 - val_loss: 0.7760 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3539 - accuracy: 0.8841 - val_loss: 0.7944 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3617 - accuracy: 0.8812 - val_loss: 0.8079 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.3490 - accuracy: 0.8783 - val_loss: 0.8169 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 15s 664ms/step - loss: 0.3426 - accuracy: 0.8986 - val_loss: 0.8165 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.3493 - accuracy: 0.9014 - val_loss: 0.8160 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 14s 627ms/step - loss: 0.3823 - accuracy: 0.8609 - val_loss: 0.8156 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3694 - accuracy: 0.8870 - val_loss: 0.8121 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3527 - accuracy: 0.8841 - val_loss: 0.8223 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3486 - accuracy: 0.8899 - val_loss: 0.8285 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3720 - accuracy: 0.8754 - val_loss: 0.8185 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.3176 - accuracy: 0.8870 - val_loss: 0.8142 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "22/22 [==============================] - 14s 627ms/step - loss: 0.3466 - accuracy: 0.8725 - val_loss: 0.8108 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "22/22 [==============================] - 14s 625ms/step - loss: 0.3657 - accuracy: 0.8667 - val_loss: 0.7869 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.3543 - accuracy: 0.8870 - val_loss: 0.7646 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3680 - accuracy: 0.8812 - val_loss: 0.7706 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.3661 - accuracy: 0.8696 - val_loss: 0.7675 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.3283 - accuracy: 0.8986 - val_loss: 0.7946 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "22/22 [==============================] - 14s 639ms/step - loss: 0.3660 - accuracy: 0.8696 - val_loss: 0.8006 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.3228 - accuracy: 0.8841 - val_loss: 0.7934 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.3666 - accuracy: 0.8725 - val_loss: 0.8030 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "22/22 [==============================] - 14s 649ms/step - loss: 0.3435 - accuracy: 0.8725 - val_loss: 0.7979 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.3628 - accuracy: 0.8638 - val_loss: 0.7796 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3094 - accuracy: 0.9014 - val_loss: 0.7773 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "22/22 [==============================] - 14s 640ms/step - loss: 0.3236 - accuracy: 0.8812 - val_loss: 0.7751 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "22/22 [==============================] - 14s 639ms/step - loss: 0.3443 - accuracy: 0.8754 - val_loss: 0.7726 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.3281 - accuracy: 0.9072 - val_loss: 0.7767 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.2909 - accuracy: 0.9101 - val_loss: 0.7702 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "22/22 [==============================] - 14s 639ms/step - loss: 0.3266 - accuracy: 0.8696 - val_loss: 0.7726 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.3464 - accuracy: 0.8696 - val_loss: 0.7921 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3337 - accuracy: 0.8841 - val_loss: 0.7874 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "22/22 [==============================] - 14s 620ms/step - loss: 0.3411 - accuracy: 0.8899 - val_loss: 0.7791 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.3295 - accuracy: 0.8899 - val_loss: 0.7688 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "22/22 [==============================] - 14s 628ms/step - loss: 0.3677 - accuracy: 0.8696 - val_loss: 0.7884 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.3604 - accuracy: 0.8812 - val_loss: 0.8008 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "22/22 [==============================] - 14s 620ms/step - loss: 0.3560 - accuracy: 0.8812 - val_loss: 0.7768 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.3157 - accuracy: 0.8841 - val_loss: 0.7832 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "22/22 [==============================] - 14s 618ms/step - loss: 0.3009 - accuracy: 0.8986 - val_loss: 0.7894 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.3068 - accuracy: 0.8928 - val_loss: 0.7916 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "22/22 [==============================] - 13s 613ms/step - loss: 0.3602 - accuracy: 0.8812 - val_loss: 0.7978 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3593 - accuracy: 0.8696 - val_loss: 0.8046 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.2690 - accuracy: 0.9072 - val_loss: 0.7845 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.3765 - accuracy: 0.8870 - val_loss: 0.7790 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3040 - accuracy: 0.8986 - val_loss: 0.7794 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.3155 - accuracy: 0.8812 - val_loss: 0.7693 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "22/22 [==============================] - 14s 628ms/step - loss: 0.3574 - accuracy: 0.8754 - val_loss: 0.7657 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3084 - accuracy: 0.8957 - val_loss: 0.7632 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.3326 - accuracy: 0.8928 - val_loss: 0.7439 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3193 - accuracy: 0.8899 - val_loss: 0.7360 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3006 - accuracy: 0.8986 - val_loss: 0.7354 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "22/22 [==============================] - 14s 630ms/step - loss: 0.3066 - accuracy: 0.9072 - val_loss: 0.7527 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3180 - accuracy: 0.9014 - val_loss: 0.7739 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.3002 - accuracy: 0.9072 - val_loss: 0.7759 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.3412 - accuracy: 0.8725 - val_loss: 0.7663 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.2866 - accuracy: 0.9014 - val_loss: 0.7660 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "22/22 [==============================] - 14s 643ms/step - loss: 0.3116 - accuracy: 0.9043 - val_loss: 0.7589 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3268 - accuracy: 0.9101 - val_loss: 0.7705 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "22/22 [==============================] - 14s 639ms/step - loss: 0.3352 - accuracy: 0.8812 - val_loss: 0.7558 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.3029 - accuracy: 0.8899 - val_loss: 0.7538 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.2977 - accuracy: 0.9101 - val_loss: 0.7483 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.3481 - accuracy: 0.8841 - val_loss: 0.7401 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.2810 - accuracy: 0.9159 - val_loss: 0.7426 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.2973 - accuracy: 0.8957 - val_loss: 0.7577 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "22/22 [==============================] - 14s 645ms/step - loss: 0.3066 - accuracy: 0.9043 - val_loss: 0.7634 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "22/22 [==============================] - 14s 642ms/step - loss: 0.3726 - accuracy: 0.8899 - val_loss: 0.7787 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3242 - accuracy: 0.8841 - val_loss: 0.7707 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.2794 - accuracy: 0.9072 - val_loss: 0.7612 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.3091 - accuracy: 0.8899 - val_loss: 0.7605 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.3068 - accuracy: 0.9072 - val_loss: 0.7613 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.2974 - accuracy: 0.9101 - val_loss: 0.7663 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.3270 - accuracy: 0.9072 - val_loss: 0.7770 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "22/22 [==============================] - 14s 629ms/step - loss: 0.2917 - accuracy: 0.8957 - val_loss: 0.7845 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.2642 - accuracy: 0.9246 - val_loss: 0.7883 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.2682 - accuracy: 0.9130 - val_loss: 0.7785 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.2971 - accuracy: 0.9072 - val_loss: 0.7687 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.3306 - accuracy: 0.8841 - val_loss: 0.7852 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "22/22 [==============================] - 14s 632ms/step - loss: 0.2543 - accuracy: 0.9159 - val_loss: 0.7793 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.2360 - accuracy: 0.9246 - val_loss: 0.7976 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.2708 - accuracy: 0.9159 - val_loss: 0.8072 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.3204 - accuracy: 0.8957 - val_loss: 0.8068 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "22/22 [==============================] - 14s 638ms/step - loss: 0.3518 - accuracy: 0.9043 - val_loss: 0.8087 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.2959 - accuracy: 0.8986 - val_loss: 0.7961 - val_accuracy: 0.6316 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "22/22 [==============================] - 14s 639ms/step - loss: 0.2530 - accuracy: 0.9043 - val_loss: 0.7836 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.2583 - accuracy: 0.9188 - val_loss: 0.7841 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "22/22 [==============================] - 14s 641ms/step - loss: 0.2819 - accuracy: 0.8986 - val_loss: 0.7873 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "22/22 [==============================] - 14s 657ms/step - loss: 0.2528 - accuracy: 0.9072 - val_loss: 0.7817 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "22/22 [==============================] - 14s 655ms/step - loss: 0.3041 - accuracy: 0.8957 - val_loss: 0.7677 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "22/22 [==============================] - 14s 648ms/step - loss: 0.3346 - accuracy: 0.8986 - val_loss: 0.7488 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "22/22 [==============================] - 14s 644ms/step - loss: 0.2458 - accuracy: 0.9101 - val_loss: 0.7540 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.2815 - accuracy: 0.9130 - val_loss: 0.7665 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.2391 - accuracy: 0.9246 - val_loss: 0.7754 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "22/22 [==============================] - 14s 647ms/step - loss: 0.2890 - accuracy: 0.9043 - val_loss: 0.7884 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "22/22 [==============================] - 14s 643ms/step - loss: 0.3087 - accuracy: 0.8928 - val_loss: 0.7881 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "22/22 [==============================] - 14s 641ms/step - loss: 0.2458 - accuracy: 0.9159 - val_loss: 0.7732 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "22/22 [==============================] - 14s 643ms/step - loss: 0.2718 - accuracy: 0.9072 - val_loss: 0.7757 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "22/22 [==============================] - 14s 645ms/step - loss: 0.2842 - accuracy: 0.9130 - val_loss: 0.7852 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "22/22 [==============================] - 14s 649ms/step - loss: 0.3098 - accuracy: 0.9130 - val_loss: 0.7715 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "22/22 [==============================] - 14s 641ms/step - loss: 0.2609 - accuracy: 0.9043 - val_loss: 0.7589 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "22/22 [==============================] - 14s 635ms/step - loss: 0.2702 - accuracy: 0.9072 - val_loss: 0.7555 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.2535 - accuracy: 0.9130 - val_loss: 0.7395 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.2402 - accuracy: 0.9391 - val_loss: 0.7421 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "22/22 [==============================] - 14s 634ms/step - loss: 0.2529 - accuracy: 0.9159 - val_loss: 0.7529 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.2571 - accuracy: 0.9304 - val_loss: 0.7658 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "22/22 [==============================] - 14s 644ms/step - loss: 0.2674 - accuracy: 0.9159 - val_loss: 0.7598 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "22/22 [==============================] - 14s 631ms/step - loss: 0.2803 - accuracy: 0.9043 - val_loss: 0.7453 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "22/22 [==============================] - 14s 638ms/step - loss: 0.2643 - accuracy: 0.9014 - val_loss: 0.7618 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "22/22 [==============================] - 14s 646ms/step - loss: 0.2235 - accuracy: 0.9333 - val_loss: 0.7417 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "22/22 [==============================] - 14s 642ms/step - loss: 0.2866 - accuracy: 0.9101 - val_loss: 0.7535 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "22/22 [==============================] - 14s 647ms/step - loss: 0.2659 - accuracy: 0.9217 - val_loss: 0.7793 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "22/22 [==============================] - 14s 636ms/step - loss: 0.2672 - accuracy: 0.9217 - val_loss: 0.7704 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "22/22 [==============================] - 14s 643ms/step - loss: 0.3047 - accuracy: 0.9101 - val_loss: 0.7790 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "22/22 [==============================] - 14s 637ms/step - loss: 0.2410 - accuracy: 0.9072 - val_loss: 0.7772 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "22/22 [==============================] - 14s 651ms/step - loss: 0.2535 - accuracy: 0.9246 - val_loss: 0.7681 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.2634 - accuracy: 0.9043 - val_loss: 0.7615 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "22/22 [==============================] - 14s 619ms/step - loss: 0.2666 - accuracy: 0.9159 - val_loss: 0.7582 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "22/22 [==============================] - 14s 621ms/step - loss: 0.2127 - accuracy: 0.9420 - val_loss: 0.7529 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "22/22 [==============================] - 14s 621ms/step - loss: 0.2238 - accuracy: 0.9449 - val_loss: 0.7601 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "22/22 [==============================] - 14s 623ms/step - loss: 0.2816 - accuracy: 0.9101 - val_loss: 0.7651 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "22/22 [==============================] - 14s 623ms/step - loss: 0.2649 - accuracy: 0.9130 - val_loss: 0.7531 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "22/22 [==============================] - 14s 627ms/step - loss: 0.2465 - accuracy: 0.9188 - val_loss: 0.7956 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "22/22 [==============================] - 14s 633ms/step - loss: 0.2355 - accuracy: 0.9275 - val_loss: 0.8059 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "22/22 [==============================] - 14s 615ms/step - loss: 0.2140 - accuracy: 0.9333 - val_loss: 0.7931 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "22/22 [==============================] - 13s 604ms/step - loss: 0.2238 - accuracy: 0.9246 - val_loss: 0.7869 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "22/22 [==============================] - 13s 605ms/step - loss: 0.2168 - accuracy: 0.9362 - val_loss: 0.7961 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "22/22 [==============================] - 13s 605ms/step - loss: 0.2879 - accuracy: 0.8899 - val_loss: 0.7964 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "22/22 [==============================] - 13s 601ms/step - loss: 0.2691 - accuracy: 0.9188 - val_loss: 0.7829 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "22/22 [==============================] - 13s 604ms/step - loss: 0.2365 - accuracy: 0.9275 - val_loss: 0.7726 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.2388 - accuracy: 0.9275 - val_loss: 0.7535 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "22/22 [==============================] - 13s 601ms/step - loss: 0.2626 - accuracy: 0.9188 - val_loss: 0.7792 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "22/22 [==============================] - 13s 605ms/step - loss: 0.2185 - accuracy: 0.9391 - val_loss: 0.8020 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "22/22 [==============================] - 13s 602ms/step - loss: 0.2417 - accuracy: 0.9130 - val_loss: 0.7873 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "22/22 [==============================] - 13s 602ms/step - loss: 0.2170 - accuracy: 0.9362 - val_loss: 0.7832 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "22/22 [==============================] - 13s 602ms/step - loss: 0.2684 - accuracy: 0.9101 - val_loss: 0.8053 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "22/22 [==============================] - 13s 601ms/step - loss: 0.2627 - accuracy: 0.9072 - val_loss: 0.8029 - val_accuracy: 0.6842 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "22/22 [==============================] - 13s 604ms/step - loss: 0.2216 - accuracy: 0.9275 - val_loss: 0.7894 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "22/22 [==============================] - 13s 607ms/step - loss: 0.2480 - accuracy: 0.9333 - val_loss: 0.7680 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "22/22 [==============================] - 13s 602ms/step - loss: 0.2396 - accuracy: 0.9188 - val_loss: 0.7643 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "22/22 [==============================] - 13s 601ms/step - loss: 0.2771 - accuracy: 0.9217 - val_loss: 0.7763 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "22/22 [==============================] - 13s 602ms/step - loss: 0.2057 - accuracy: 0.9362 - val_loss: 0.7587 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "22/22 [==============================] - 14s 616ms/step - loss: 0.2406 - accuracy: 0.9246 - val_loss: 0.7464 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "22/22 [==============================] - 14s 624ms/step - loss: 0.2722 - accuracy: 0.9246 - val_loss: 0.7531 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "22/22 [==============================] - 14s 626ms/step - loss: 0.2437 - accuracy: 0.9130 - val_loss: 0.7622 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "22/22 [==============================] - 14s 615ms/step - loss: 0.2608 - accuracy: 0.9246 - val_loss: 0.7737 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "22/22 [==============================] - 14s 615ms/step - loss: 0.2227 - accuracy: 0.9333 - val_loss: 0.7861 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "22/22 [==============================] - 14s 617ms/step - loss: 0.2266 - accuracy: 0.9159 - val_loss: 0.7753 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "22/22 [==============================] - 14s 620ms/step - loss: 0.2672 - accuracy: 0.9188 - val_loss: 0.7606 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "22/22 [==============================] - 14s 622ms/step - loss: 0.2344 - accuracy: 0.9246 - val_loss: 0.7711 - val_accuracy: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "22/22 [==============================] - 14s 618ms/step - loss: 0.2261 - accuracy: 0.9217 - val_loss: 0.7848 - val_accuracy: 0.7368 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d719d4470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "530Lze2gwwpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dd5d2d42-acb2-4bdb-e133-f8ed53211e6a"
      },
      "source": [
        "model.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 287ms/step - loss: 0.0446 - accuracy: 0.9826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.044570181518793106, 0.9826086759567261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKZtIuhvtHPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d8f3dcff-2676-44e4-cf07-f03a3adf38ab"
      },
      "source": [
        "model.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 290ms/step - loss: 0.0896 - accuracy: 0.9768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08958088606595993, 0.9768115878105164]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIk3tCbFpLuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c0cb6977-5785-45bc-e160-e5429200005b"
      },
      "source": [
        "model.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 287ms/step - loss: 0.1789 - accuracy: 0.9391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1789371520280838, 0.939130425453186]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJUS9oMl4dAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1= model.predict(test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ZjtNqExE-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0f2997a1-0ea1-4092-d392-836595e965fb"
      },
      "source": [
        "labels = model.predict(test_img)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "      <td>kuchipudi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image     target\n",
              "0  508.jpg     odissi\n",
              "1  246.jpg     odissi\n",
              "2  473.jpg     odissi\n",
              "3  485.jpg     odissi\n",
              "4  128.jpg  kuchipudi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9v8PObc4kB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "48f41b75-feb8-4c05-e4ed-defdc80897fe"
      },
      "source": [
        "submission['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odissi           73\n",
              "kathakali        27\n",
              "mohiniyattam     16\n",
              "manipuri         15\n",
              "kuchipudi        10\n",
              "bharatanatyam     6\n",
              "sattriya          6\n",
              "kathak            3\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbzBlX7kiOIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e8cbb231-bf8a-437b-dc83-71f755b8bd1e"
      },
      "source": [
        "labels = model.predict(test_img)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "      <td>kuchipudi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "      <td>kuchipudi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "      <td>kuchipudi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image     target\n",
              "0  508.jpg  kuchipudi\n",
              "1  246.jpg  kuchipudi\n",
              "2  473.jpg     odissi\n",
              "3  485.jpg     odissi\n",
              "4  128.jpg  kuchipudi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2WUG4hvqYSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('/content/drive/My Drive/dataset/vgg16.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKK-t29YLJke",
        "colab_type": "text"
      },
      "source": [
        "## VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zZ7crAHKLEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d5e6d277-b8d6-4967-c067-718dc3a27d5b"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input\n",
        "base_model_3=VGG19(include_top=False, weights='imagenet',input_shape=(img_h,img_w,3), pooling='max')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYIiUT5pKK7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in base_model_3.layers[:-4]:\n",
        "    layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6IjjdOFKKH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vgg19-4\n",
        "model_3=Sequential()\n",
        "model_3.add(base_model_3)\n",
        "model_3.add(Flatten())\n",
        "#model_3.add(BatchNormalization())\n",
        "#model_3.add(Dropout(0.2))\n",
        "\n",
        "model_3.add(Dense(512, activation='relu'))\n",
        "#model_3.add(BatchNormalization())\n",
        "model_3.add(Dropout(0.2))\n",
        "\n",
        "model_3.add(Dense(256, activation='relu'))\n",
        "model_3.add(Dropout(0.2))\n",
        "model_3.add(Dense(128, activation='relu'))\n",
        "#model_3.add(BatchNormalization())\n",
        "model_3.add(Dense(8,activation='softmax'))\n",
        "\n",
        "model_3.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLdjQDTNRTfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vgg19-3\n",
        "model_3=Sequential()\n",
        "model_3.add(base_model_3)\n",
        "model_3.add(Flatten())\n",
        "#model_3.add(BatchNormalization())\n",
        "#model_3.add(Dropout(0.2))\n",
        "model_3.add(Dense(512, activation='relu'))\n",
        "#model_3.add(BatchNormalization())\n",
        "model_3.add(Dropout(0.2))\n",
        "model_3.add(Dense(128, activation='relu'))\n",
        "#model_3.add(BatchNormalization())\n",
        "model_3.add(Dense(8,activation='softmax'))\n",
        "\n",
        "model_3.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UQEb_-0KJ2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "175d8a77-9f9c-43fc-fce5-dfbf2d608d75"
      },
      "source": [
        "model_3.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=16),epochs=200,callbacks=callbacks,\n",
        "          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=16),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.2061 - accuracy: 0.9420 - val_loss: 0.3218 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 2/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1935 - accuracy: 0.9536 - val_loss: 0.3276 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 3/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1764 - accuracy: 0.9420 - val_loss: 0.3280 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 4/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1879 - accuracy: 0.9391 - val_loss: 0.3316 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 5/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1453 - accuracy: 0.9536 - val_loss: 0.3373 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 6/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1607 - accuracy: 0.9478 - val_loss: 0.3422 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 7/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1439 - accuracy: 0.9565 - val_loss: 0.3458 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 8/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.2010 - accuracy: 0.9217 - val_loss: 0.3507 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 9/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1684 - accuracy: 0.9449 - val_loss: 0.3499 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 10/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1794 - accuracy: 0.9420 - val_loss: 0.3535 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 11/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.1627 - accuracy: 0.9565 - val_loss: 0.3531 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 12/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1834 - accuracy: 0.9391 - val_loss: 0.3461 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 13/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1671 - accuracy: 0.9362 - val_loss: 0.3518 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 14/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1624 - accuracy: 0.9449 - val_loss: 0.3549 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 15/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1963 - accuracy: 0.9362 - val_loss: 0.3456 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 16/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.3462 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 17/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1402 - accuracy: 0.9768 - val_loss: 0.3417 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 18/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1534 - accuracy: 0.9478 - val_loss: 0.3395 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 19/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1611 - accuracy: 0.9449 - val_loss: 0.3396 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 20/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1439 - accuracy: 0.9565 - val_loss: 0.3389 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 21/200\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1428 - accuracy: 0.9565 - val_loss: 0.3403 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 22/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1502 - accuracy: 0.9478 - val_loss: 0.3372 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 23/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1438 - accuracy: 0.9507 - val_loss: 0.3351 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 24/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1642 - accuracy: 0.9478 - val_loss: 0.3339 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 25/200\n",
            "22/22 [==============================] - 4s 170ms/step - loss: 0.1268 - accuracy: 0.9536 - val_loss: 0.3415 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 26/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1392 - accuracy: 0.9507 - val_loss: 0.3398 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 27/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1821 - accuracy: 0.9420 - val_loss: 0.3395 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 28/200\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1477 - accuracy: 0.9478 - val_loss: 0.3285 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 29/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.1310 - accuracy: 0.9594 - val_loss: 0.3302 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 30/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1525 - accuracy: 0.9536 - val_loss: 0.3370 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 31/200\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1619 - accuracy: 0.9478 - val_loss: 0.3420 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 32/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.1609 - accuracy: 0.9449 - val_loss: 0.3324 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 33/200\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1475 - accuracy: 0.9536 - val_loss: 0.3254 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 34/200\n",
            "22/22 [==============================] - 4s 170ms/step - loss: 0.1479 - accuracy: 0.9478 - val_loss: 0.3210 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 35/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1422 - accuracy: 0.9478 - val_loss: 0.3274 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 36/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1463 - accuracy: 0.9565 - val_loss: 0.3359 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 37/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1689 - accuracy: 0.9275 - val_loss: 0.3429 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 38/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1249 - accuracy: 0.9594 - val_loss: 0.3500 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 39/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1418 - accuracy: 0.9391 - val_loss: 0.3492 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 40/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1552 - accuracy: 0.9507 - val_loss: 0.3642 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 41/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1431 - accuracy: 0.9507 - val_loss: 0.3669 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 42/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1742 - accuracy: 0.9449 - val_loss: 0.3712 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 43/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.1217 - accuracy: 0.9565 - val_loss: 0.3700 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 44/200\n",
            "22/22 [==============================] - 4s 171ms/step - loss: 0.1409 - accuracy: 0.9565 - val_loss: 0.3617 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 45/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1309 - accuracy: 0.9681 - val_loss: 0.3568 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 46/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1513 - accuracy: 0.9594 - val_loss: 0.3595 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 47/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1236 - accuracy: 0.9623 - val_loss: 0.3649 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 48/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1644 - accuracy: 0.9652 - val_loss: 0.3614 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 49/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1332 - accuracy: 0.9652 - val_loss: 0.3560 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 50/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1449 - accuracy: 0.9594 - val_loss: 0.3542 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 51/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1257 - accuracy: 0.9623 - val_loss: 0.3595 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 52/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1351 - accuracy: 0.9594 - val_loss: 0.3601 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 53/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1258 - accuracy: 0.9623 - val_loss: 0.3539 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 54/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1017 - accuracy: 0.9739 - val_loss: 0.3575 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 55/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1444 - accuracy: 0.9449 - val_loss: 0.3564 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 56/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1247 - accuracy: 0.9623 - val_loss: 0.3554 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 57/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1642 - accuracy: 0.9362 - val_loss: 0.3559 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 58/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1228 - accuracy: 0.9681 - val_loss: 0.3574 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 59/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.1207 - accuracy: 0.9652 - val_loss: 0.3616 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 60/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1570 - accuracy: 0.9391 - val_loss: 0.3648 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 61/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0971 - accuracy: 0.9623 - val_loss: 0.3636 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1002 - accuracy: 0.9797 - val_loss: 0.3531 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1229 - accuracy: 0.9681 - val_loss: 0.3516 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1613 - accuracy: 0.9565 - val_loss: 0.3519 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1465 - accuracy: 0.9594 - val_loss: 0.3566 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1256 - accuracy: 0.9623 - val_loss: 0.3568 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1487 - accuracy: 0.9565 - val_loss: 0.3621 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.1137 - accuracy: 0.9623 - val_loss: 0.3715 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.1218 - accuracy: 0.9652 - val_loss: 0.3798 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1242 - accuracy: 0.9652 - val_loss: 0.3805 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0999 - accuracy: 0.9623 - val_loss: 0.3805 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1334 - accuracy: 0.9536 - val_loss: 0.3839 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1273 - accuracy: 0.9623 - val_loss: 0.3817 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1383 - accuracy: 0.9594 - val_loss: 0.3771 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "22/22 [==============================] - 4s 177ms/step - loss: 0.0998 - accuracy: 0.9739 - val_loss: 0.3856 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0935 - accuracy: 0.9768 - val_loss: 0.3854 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.3795 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1253 - accuracy: 0.9565 - val_loss: 0.3713 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0896 - accuracy: 0.9739 - val_loss: 0.3752 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1247 - accuracy: 0.9681 - val_loss: 0.3672 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1253 - accuracy: 0.9623 - val_loss: 0.3693 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1741 - accuracy: 0.9420 - val_loss: 0.3762 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1078 - accuracy: 0.9594 - val_loss: 0.3815 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0891 - accuracy: 0.9681 - val_loss: 0.3848 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1318 - accuracy: 0.9652 - val_loss: 0.3792 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1278 - accuracy: 0.9652 - val_loss: 0.3849 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1191 - accuracy: 0.9507 - val_loss: 0.3762 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0871 - accuracy: 0.9739 - val_loss: 0.3713 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1080 - accuracy: 0.9739 - val_loss: 0.3688 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0864 - accuracy: 0.9652 - val_loss: 0.3714 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1004 - accuracy: 0.9652 - val_loss: 0.3642 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0970 - accuracy: 0.9768 - val_loss: 0.3633 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0934 - accuracy: 0.9739 - val_loss: 0.3603 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.0897 - accuracy: 0.9710 - val_loss: 0.3608 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0953 - accuracy: 0.9681 - val_loss: 0.3535 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1239 - accuracy: 0.9594 - val_loss: 0.3485 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1244 - accuracy: 0.9536 - val_loss: 0.3451 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.1059 - accuracy: 0.9652 - val_loss: 0.3625 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.0940 - accuracy: 0.9681 - val_loss: 0.3695 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "22/22 [==============================] - 4s 162ms/step - loss: 0.0844 - accuracy: 0.9768 - val_loss: 0.3731 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0948 - accuracy: 0.9739 - val_loss: 0.3695 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0995 - accuracy: 0.9739 - val_loss: 0.3720 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1295 - accuracy: 0.9565 - val_loss: 0.3606 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0906 - accuracy: 0.9739 - val_loss: 0.3627 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1016 - accuracy: 0.9739 - val_loss: 0.3663 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0794 - accuracy: 0.9826 - val_loss: 0.3709 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0942 - accuracy: 0.9768 - val_loss: 0.3828 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0809 - accuracy: 0.9797 - val_loss: 0.3701 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.3615 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0875 - accuracy: 0.9739 - val_loss: 0.3579 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0961 - accuracy: 0.9623 - val_loss: 0.3532 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0990 - accuracy: 0.9710 - val_loss: 0.3445 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0877 - accuracy: 0.9681 - val_loss: 0.3491 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1024 - accuracy: 0.9710 - val_loss: 0.3490 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0723 - accuracy: 0.9855 - val_loss: 0.3579 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0910 - accuracy: 0.9739 - val_loss: 0.3590 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0794 - accuracy: 0.9739 - val_loss: 0.3647 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1213 - accuracy: 0.9652 - val_loss: 0.3758 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0967 - accuracy: 0.9652 - val_loss: 0.3756 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.1095 - accuracy: 0.9623 - val_loss: 0.3738 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0912 - accuracy: 0.9710 - val_loss: 0.3581 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1138 - accuracy: 0.9768 - val_loss: 0.3585 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1182 - accuracy: 0.9623 - val_loss: 0.3624 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.1056 - accuracy: 0.9710 - val_loss: 0.3654 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.0817 - accuracy: 0.9855 - val_loss: 0.3686 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1240 - accuracy: 0.9652 - val_loss: 0.3720 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1089 - accuracy: 0.9739 - val_loss: 0.3647 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0884 - accuracy: 0.9797 - val_loss: 0.3617 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0932 - accuracy: 0.9710 - val_loss: 0.3640 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0998 - accuracy: 0.9710 - val_loss: 0.3555 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0567 - accuracy: 0.9884 - val_loss: 0.3577 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0666 - accuracy: 0.9768 - val_loss: 0.3586 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0988 - accuracy: 0.9768 - val_loss: 0.3674 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0863 - accuracy: 0.9826 - val_loss: 0.3694 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0864 - accuracy: 0.9652 - val_loss: 0.3737 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0997 - accuracy: 0.9739 - val_loss: 0.3832 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.0654 - accuracy: 0.9855 - val_loss: 0.3805 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0930 - accuracy: 0.9710 - val_loss: 0.3884 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0731 - accuracy: 0.9826 - val_loss: 0.3975 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0953 - accuracy: 0.9739 - val_loss: 0.3975 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 0.4068 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0798 - accuracy: 0.9710 - val_loss: 0.4146 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "22/22 [==============================] - 4s 169ms/step - loss: 0.0987 - accuracy: 0.9710 - val_loss: 0.4065 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "22/22 [==============================] - 4s 168ms/step - loss: 0.0897 - accuracy: 0.9797 - val_loss: 0.3941 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.3961 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0462 - accuracy: 0.9942 - val_loss: 0.3962 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0637 - accuracy: 0.9884 - val_loss: 0.4047 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0723 - accuracy: 0.9797 - val_loss: 0.4008 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0801 - accuracy: 0.9797 - val_loss: 0.4027 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0889 - accuracy: 0.9710 - val_loss: 0.4032 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 0.3981 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0533 - accuracy: 0.9826 - val_loss: 0.3930 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1000 - accuracy: 0.9768 - val_loss: 0.4012 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0685 - accuracy: 0.9797 - val_loss: 0.3954 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.1051 - accuracy: 0.9623 - val_loss: 0.3865 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1149 - accuracy: 0.9652 - val_loss: 0.3870 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0544 - accuracy: 0.9913 - val_loss: 0.3874 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0821 - accuracy: 0.9739 - val_loss: 0.3804 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0817 - accuracy: 0.9768 - val_loss: 0.3867 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 0.3899 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0705 - accuracy: 0.9768 - val_loss: 0.3916 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0707 - accuracy: 0.9797 - val_loss: 0.3970 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0805 - accuracy: 0.9623 - val_loss: 0.3942 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0832 - accuracy: 0.9739 - val_loss: 0.3843 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0702 - accuracy: 0.9826 - val_loss: 0.3787 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0868 - accuracy: 0.9739 - val_loss: 0.3784 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0893 - accuracy: 0.9739 - val_loss: 0.3814 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0585 - accuracy: 0.9797 - val_loss: 0.3893 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0595 - accuracy: 0.9884 - val_loss: 0.3902 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0965 - accuracy: 0.9681 - val_loss: 0.3917 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0826 - accuracy: 0.9884 - val_loss: 0.3872 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0920 - accuracy: 0.9710 - val_loss: 0.3905 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "22/22 [==============================] - 4s 163ms/step - loss: 0.0627 - accuracy: 0.9797 - val_loss: 0.4043 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0507 - accuracy: 0.9855 - val_loss: 0.4087 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0849 - accuracy: 0.9797 - val_loss: 0.4064 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0637 - accuracy: 0.9855 - val_loss: 0.4213 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0500 - accuracy: 0.9884 - val_loss: 0.4229 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "22/22 [==============================] - 4s 172ms/step - loss: 0.0630 - accuracy: 0.9768 - val_loss: 0.4197 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0834 - accuracy: 0.9739 - val_loss: 0.4128 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0501 - accuracy: 0.9855 - val_loss: 0.4091 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0563 - accuracy: 0.9797 - val_loss: 0.4065 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0592 - accuracy: 0.9884 - val_loss: 0.4011 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0629 - accuracy: 0.9797 - val_loss: 0.4130 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.0545 - accuracy: 0.9884 - val_loss: 0.4020 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.3975 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0777 - accuracy: 0.9768 - val_loss: 0.4051 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0547 - accuracy: 0.9797 - val_loss: 0.4064 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0597 - accuracy: 0.9884 - val_loss: 0.3962 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0703 - accuracy: 0.9768 - val_loss: 0.3910 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.3873 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0459 - accuracy: 0.9913 - val_loss: 0.3841 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "22/22 [==============================] - 4s 167ms/step - loss: 0.1007 - accuracy: 0.9710 - val_loss: 0.3954 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.3797 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0630 - accuracy: 0.9884 - val_loss: 0.3829 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0495 - accuracy: 0.9884 - val_loss: 0.3835 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "22/22 [==============================] - 4s 165ms/step - loss: 0.0497 - accuracy: 0.9884 - val_loss: 0.3865 - val_accuracy: 0.8421 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "22/22 [==============================] - 4s 164ms/step - loss: 0.0609 - accuracy: 0.9826 - val_loss: 0.3863 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0866 - accuracy: 0.9710 - val_loss: 0.3938 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0386 - accuracy: 0.9913 - val_loss: 0.4038 - val_accuracy: 0.8947 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "22/22 [==============================] - 4s 166ms/step - loss: 0.0430 - accuracy: 0.9913 - val_loss: 0.4042 - val_accuracy: 0.8947 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d74fa9358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ9Jc8c30mtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c743d082-f92a-4ef0-ce77-f69577428056"
      },
      "source": [
        "model_3.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 291ms/step - loss: 0.0395 - accuracy: 0.9913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03948166221380234, 0.991304337978363]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvRoTP-T0mjI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "06274f4f-dded-484f-ff6b-2d0c48c59d40"
      },
      "source": [
        "labels = model_3.predict(test_img)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0  508.jpg         odissi\n",
              "1  246.jpg         odissi\n",
              "2  473.jpg         odissi\n",
              "3  485.jpg         odissi\n",
              "4  128.jpg  bharatanatyam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3FE37qc3sEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "123562b5-d51c-43a1-d88d-480c5c2f29b2"
      },
      "source": [
        "submission['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odissi           46\n",
              "bharatanatyam    31\n",
              "kathakali        21\n",
              "kathak           20\n",
              "kuchipudi        14\n",
              "mohiniyattam     13\n",
              "manipuri          6\n",
              "sattriya          5\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX5Op15By2jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "09c052b9-ff2a-4bae-ff6d-6866d6174dea"
      },
      "source": [
        "model_3.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 3s 297ms/step - loss: 0.1603 - accuracy: 0.9594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1603143811225891, 0.9594202637672424]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bnux8M_MrYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "32822fe2-e9f4-4f8d-b619-e179cb87fff8"
      },
      "source": [
        "labels = model_3.predict(test_img)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>508.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>473.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>485.jpg</td>\n",
              "      <td>odissi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>128.jpg</td>\n",
              "      <td>bharatanatyam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image         target\n",
              "0  508.jpg  bharatanatyam\n",
              "1  246.jpg         odissi\n",
              "2  473.jpg         odissi\n",
              "3  485.jpg         odissi\n",
              "4  128.jpg  bharatanatyam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drq1vk9s0wbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "24c5c41c-ce91-4b23-a8aa-bff30397e40c"
      },
      "source": [
        "submission['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odissi           45\n",
              "bharatanatyam    34\n",
              "kathakali        23\n",
              "kathak           20\n",
              "kuchipudi        12\n",
              "mohiniyattam     12\n",
              "manipuri          6\n",
              "sattriya          4\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDrAQmUKJwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('/content/drive/My Drive/dataset/vgg19.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYKA3CZLbMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOk_Ubb47Mn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "dc8db6b6-572d-449d-e342-c911b74df7c0"
      },
      "source": [
        "label = [np.argmax(i) for i in y]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odissi           30\n",
              "kuchipudi        29\n",
              "kathakali        23\n",
              "kathak           23\n",
              "bharatanatyam    22\n",
              "mohiniyattam     13\n",
              "sattriya         10\n",
              "manipuri          6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16FhbELn4zXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "60064eda-f784-4d91-9a7e-cf6ad285ef63"
      },
      "source": [
        "label = [np.argmax(i) for i in y]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odissi           30\n",
              "kuchipudi        29\n",
              "kathakali        23\n",
              "kathak           23\n",
              "bharatanatyam    22\n",
              "mohiniyattam     13\n",
              "sattriya         10\n",
              "manipuri          6\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiyleYS446kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('/content/drive/My Drive/dataset/vgg16+19.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vehYZKTE5Fse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import concatenate\n",
        "def stacking_ensemble(members,input_shape,n_classes):\n",
        "  commonInput = Input(shape=input_shape)\n",
        "  out=[]\n",
        "\n",
        "  for model in members:\n",
        "    #model._name= model._name+\"test\"+ str(members.index(model)+1)\n",
        "    model._name= model.get_layer(index = 0)._name +\"-test\"+ str(members.index(model)+1)\n",
        "    out.append(model(commonInput))\n",
        "\n",
        "  modeltmp = concatenate(out,axis=-1)\n",
        "  modeltmp = Dense(32, activation='relu')(modeltmp)\n",
        "  modeltmp = Dense(16, activation='relu')(modeltmp)\n",
        "  modeltmp = Dense(n_classes, activation='softmax')(modeltmp)\n",
        "  stacked_model = Model(commonInput,modeltmp)\n",
        "  stacked_model.compile( loss='categorical_crossentropy',optimizer= 'adam', metrics=['accuracy'])\n",
        "\n",
        "  return stacked_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_4rvw952_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "members=[model,model_3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhVOmVSB52s4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "4c94b860-ec0e-45f0-a024-e34b80608fed"
      },
      "source": [
        "stacked_model= stacking_ensemble(members,(img_h,img_w,3),8)\n",
        "stacked_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vgg16-test1 (Sequential)        (None, 8)            15044040    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "vgg19-test2 (Sequential)        (None, 8)            20353736    input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16)           0           vgg16-test1[1][0]                \n",
            "                                                                 vgg19-test2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 32)           544         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 16)           528         dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 8)            136         dense_22[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 35,398,984\n",
            "Trainable params: 10,099,144\n",
            "Non-trainable params: 25,299,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpiYZMT459N7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "710a055f-dc4f-4898-a746-1eebf4ce4403"
      },
      "source": [
        "stacked_model.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),epochs=200,callbacks=callbacks,\n",
        "          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 4s 343ms/step - loss: 1.3793 - accuracy: 0.5130 - val_loss: 1.3525 - val_accuracy: 0.4737 - lr: 1.0000e-05\n",
            "Epoch 49/200\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.3810 - accuracy: 0.5112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-285478c303a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m              )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1faiflq6FRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_3.evaluate(train_datagen.flow(x_train, to_categorical(y_train,8))) #epochs=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B31ILhyk6FMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = stacked_model.predict(test_img)\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\n",
        "submission.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujgwssPS6FKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " submission.to_csv('/content/drive/My Drive/dataset/stacking.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}